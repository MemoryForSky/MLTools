{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 特征选择工具包"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1、综述"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 特征选择：\n",
    "\n",
    "- 业务层特征选择\n",
    "- 技术层特征选择"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 特征选择的流程\n",
    "\n",
    "- 数据质量分析（盲选）\n",
    "- 特征质量分析（粗选、精挑细选）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2、过滤法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import toad\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from minepy import MINE\n",
    "from scipy.stats import pearsonr\n",
    "from collections import defaultdict\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_selection import f_classif, f_regression\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_diff(list1, list2):\n",
    "    \"\"\"return: 两个list之间的差集\"\"\"\n",
    "    if len(list1) > 0 and len(list2) > 0:\n",
    "        return list(np.setdiff1d(list1, list2))\n",
    "    else:\n",
    "        print('list_diff:len <= 0 !!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_unique(df):\n",
    "    \"\"\"计算每列唯一值数量，排除NA:\"\"\"\n",
    "    return df.apply(lambda x:x.nunique(), axis=0)\n",
    "\n",
    "def near_zero_var(df, freq_cut=0.95, unique_cut=10):\n",
    "    \"\"\"过滤得分最高的数据值占95%的序列\"\"\"\n",
    "    nb_unique_values = count_unique(df)\n",
    "    n_rows, _ = df.shape\n",
    "    percent_unique = 100 * nb_unique_values / n_rows\n",
    "    \n",
    "    def helper_freq(x):\n",
    "        if nb_unique_values[x.name] == 0:\n",
    "            return 0.0\n",
    "        elif nb_unique_values[x.name] == 1:\n",
    "            return 1.0\n",
    "        else:\n",
    "            t = x.value_counts()\n",
    "            return float(t.iloc[0])/t.iloc[0:].sum()\n",
    "        \n",
    "    # 只取得分最高的数据/其他数据和\n",
    "    freq_ratio = df.apply(helper_freq)\n",
    "    zerovar = (nb_unique_values == 0) | (nb_unique_values == 1)  # 全为空值或常数值\n",
    "    near_zero = ((freq_ratio >= freq_cut) & (percent_unique <= unique_cut)) | (zerovar)\n",
    "    return near_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal length (cm)    35\n",
       "sepal width (cm)     23\n",
       "petal length (cm)    43\n",
       "petal width (cm)     22\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_unique(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "\n",
    "# 转化为df\n",
    "X = pd.DataFrame.from_records(data=data.data, columns=data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm)    0.071429\n",
      "sepal width (cm)     0.209677\n",
      "petal length (cm)    0.094891\n",
      "petal width (cm)     0.239669\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sepal length (cm)    False\n",
       "sepal width (cm)     False\n",
       "petal length (cm)    False\n",
       "petal width (cm)     False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "near_zero_var(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureFilter():\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: pandas.DataFrame\n",
    "        数据集. \n",
    "    y: pandas.series or nparray\n",
    "        目标变量.\n",
    "    n_features_to_select: \n",
    "        选择特征的数.\n",
    "    only_get_index: \n",
    "        是否只返回选中特征的索引.\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, n_features_to_select=None, only_get_index=True):\n",
    "        self.cols = X.columns.tolist()\n",
    "        self.X = np.array(X)\n",
    "        self.y = np.array(y)\n",
    "        self.x_index = range(self.X.shape[1])\n",
    "        self.only_get_index = only_get_index\n",
    "        self.n_features_to_select = n_features_to_select\n",
    "        if n_features_to_select is None:\n",
    "            self.n_features_to_select = int(np.ceil(2 / 3 * self.X.shape[1]))\n",
    "            print('self.n_features_to_select:', self.n_features_to_select)\n",
    "        self.removed = []\n",
    "    \n",
    "    def _log(self, index, method):\n",
    "        print('***{}:'.format(method))\n",
    "        print('  remain feature index:\\n  {}'.format(index))\n",
    "        rmvd = list_diff(self.x_index, index)\n",
    "        self.removed += rmvd\n",
    "        print('  removed feature index:\\n  {}\\n'.format(rmvd))\n",
    "\n",
    "    def _return(self, ret, method):\n",
    "        # True代表该特征被选中\n",
    "        index = ret.get_support(indices=True)\n",
    "        self._log(index, method)\n",
    "\n",
    "        if self.only_get_index == True:\n",
    "            return index\n",
    "        else:  #返回筛选之后的X\n",
    "            return ret.transform(self.X) \n",
    "    \n",
    "    def _return_index(self, index, method):\n",
    "        # True代表该特征被选中\n",
    "        self._log(index, method)\n",
    "\n",
    "        if self.only_get_index == True:\n",
    "            return index\n",
    "        else:  #返回筛选之后的X\n",
    "            return self.X[:, index]\n",
    "    \n",
    "    def _by_kbest(self, func, method):\n",
    "        \"\"\"Filter方法\"\"\"\n",
    "        ret = SelectKBest(func, k=self.n_features_to_select).fit(self.X, self.y)\n",
    "        return self._return(ret, method)\n",
    "    \n",
    "    def by_var(self, threshold=0.16):\n",
    "        \"\"\"方差\"\"\"\n",
    "        ret = VarianceThreshold(threshold=threshold).fit(self.X)\n",
    "        return self._return(ret, 'by_var')\n",
    "    \n",
    "    def count_unique(self, df):\n",
    "        \"\"\"计算每列唯一值数量，排除NA:\"\"\"\n",
    "        return df.apply(lambda x:x.nunique(), axis=0)\n",
    "\n",
    "    def near_zero_var(self, df, freq_cut=0.95, unique_cut=10):\n",
    "        \"\"\"过滤得分最高的数据值占95%的序列\"\"\"\n",
    "        nb_unique_values = self.count_unique(df)\n",
    "        n_rows, _ = df.shape\n",
    "        percent_unique = 100 * nb_unique_values / n_rows\n",
    "\n",
    "        def helper_freq(x):\n",
    "            if nb_unique_values[x.name] == 0:\n",
    "                return 0.0\n",
    "            elif nb_unique_values[x.name] == 1:\n",
    "                return 1.0\n",
    "            else:\n",
    "                t = x.value_counts()\n",
    "                return float(t.iloc[0])/t.iloc[0:].sum()\n",
    "\n",
    "        # 只取得分最高的数据/其他数据和\n",
    "        freq_ratio = df.apply(helper_freq)\n",
    "        zerovar = (nb_unique_values == 0) | (nb_unique_values == 1)  # 全为空值或常数值\n",
    "        near_zero = ((freq_ratio >= freq_cut) & (percent_unique <= unique_cut)) | (zerovar)\n",
    "        return near_zero\n",
    "\n",
    "    def by_chi2(self):\n",
    "        \"\"\"卡方\"\"\"\n",
    "        return self._by_kbest(chi2, 'by_chi2')\n",
    "\n",
    "    def by_pearson(self):\n",
    "        \"\"\"相关系数\"\"\"\n",
    "        _pp = lambda X, Y: np.array(list(map(lambda x: pearsonr(x, Y), X.T))).T[0]\n",
    "        return self._by_kbest(_pp, 'by_pearson')\n",
    "    \n",
    "    def by_mi(self):\n",
    "        \"\"\"互信息\"\"\"\n",
    "        return self._by_kbest(mutual_info_classif, 'by_mi')\n",
    "    \n",
    "    def by_max_info(self):\n",
    "        \"\"\"最大信息系数\"\"\"\n",
    "        def _mic(x, y):\n",
    "            m = MINE()\n",
    "            m.compute_score(x, y)\n",
    "            return (m.mic(), 0.5)\n",
    "\n",
    "        _pp = lambda X, Y: np.array(list(map(lambda x: _mic(x, Y), X.T))).T[0]\n",
    "        return self._by_kbest(_pp, 'by_max_info')\n",
    "\n",
    "    def by_f_regression(self):\n",
    "        \"\"\"基于样本相关系数的检验\n",
    "        return\n",
    "        --------\n",
    "        F values of features.\n",
    "        p-values of F-scores.\n",
    "        \"\"\"\n",
    "        return self._by_kbest(f_regression, 'f_regression')\n",
    "\n",
    "    def by_f_classif(self):\n",
    "        \"\"\"基于方差分析的检验统计量f值\"\"\"\n",
    "        return self._by_kbest(f_classif, 'f_classif')\n",
    "    \n",
    "    def by_iv(self, threshold=0.02, return_iv=False):\n",
    "        \"\"\"基于iv的特征筛选\"\"\"\n",
    "        iv = np.array(list(map(lambda x: toad.stats.IV(x, self.y), self.X.T))).T\n",
    "        index = np.argwhere(iv > threshold).flatten() \n",
    "        iv_info = dict(zip(self.x_index, np.round(iv, 4)))\n",
    "        if return_iv:\n",
    "            return self._return_index(index, 'by_iv'), iv_info\n",
    "        else:\n",
    "            return self._return_index(index, 'by_iv')\n",
    "    \n",
    "    def filter_bycorr_with_orderly_cols(self, df, orderly_cols, columns=None, threshold=0.8, gap=0.1):\n",
    "        \"\"\"相关性和IV双指标过滤法\n",
    "\n",
    "        筛选流程：\n",
    "        1.按IV值降序排列特征；\n",
    "        2.对排序好的特征分别计算相关性，大于人为设定的阀值则删除（多尝试几次阈值，得到大约的特征数量即可）。\n",
    "        实现中加入了参数gap，其意义为：对于大IV的特征，其相关性阈值有所提高，可以理解为剔除IV高的特征需要更\n",
    "        高的相关性阈值。gap设置为0则该功能失效，返回选中的特征名。\n",
    "        \"\"\"\n",
    "        def _get_diff_list(a_column, a_list, removed=None):\n",
    "            \"\"\"返回a_list中不属于a_column和removed的元素！\"\"\"\n",
    "            allcols = a_list\n",
    "            if removed is not None and len(removed) > 0:\n",
    "                all_cols = [aa for aa in a_list if aa not in removed]\n",
    "            return [aa for aa in all_cols if aa != a_column]\n",
    "\n",
    "        if columns is None:\n",
    "            columns = df.columns.to_list()\n",
    "\n",
    "        result = []\n",
    "        removed = []\n",
    "        to_cal_columns = [cc for cc in orderly_cols if cc in columns]\n",
    "        cal_ed = []\n",
    "\n",
    "        for cc in to_cal_columns:\n",
    "            cal_ed.append(cc)\n",
    "            if cc not in removed:\n",
    "                tmp_cols = _get_diff_list(cc, to_cal_columns, removed=removed + cal_ed)\n",
    "                thred_diff = gap * 1.0 / (len(tmp_cols) + 1)\n",
    "                count = len(tmp_cols)\n",
    "                for tt in tmp_cols:\n",
    "                    count -= 1\n",
    "                    # 计算相关性\n",
    "                    relation = df[cc].corr(df[tt])\n",
    "                    if abs(relation) > threshold + thred_diff * count:\n",
    "                        removed.append(tt)\n",
    "\n",
    "        result = [cc for cc in to_cal_columns if cc not in removed]\n",
    "        print('After filter，remains:{}\\n'.format(len(result)))\n",
    "        return result\n",
    "    \n",
    "    def cal_mic(self, x, y):\n",
    "        m = MINE()\n",
    "        m.compute_score(x, y)\n",
    "        return m.mic()\n",
    "\n",
    "    def cal_mics(self, dfx,y): \n",
    "        \"\"\"\n",
    "        dfx: dataframe\n",
    "        y: serises\n",
    "        \"\"\"\n",
    "        return dfx.apply(lambda x: self.cal_mic(x, y))\n",
    "\n",
    "    def mrmr(self, dfx, y, n):\n",
    "        \"\"\"最小冗余最大相关\n",
    "        \n",
    "        1、相关性分析：计算特征与目标变量间的相关性，度量方式可依据数据类型的不同使用互信息、最大信息系数和方差检验等，记为C；\n",
    "        2、冗余性分析：计算特征间的相关性，度量方式可使用互信息、最大信息系数和相关系数等，记为R；\n",
    "        3、最后使用Max(C-R)或Max(C/R)综合考虑相关性和冗余性；\n",
    "        \n",
    "        Parameter:\n",
    "        ----------\n",
    "        n: 待选的特征数\n",
    "        \"\"\"\n",
    "        # 记录已选择的列\n",
    "        selected = []\n",
    "        # 记录特征MIC \n",
    "        mic_dict = {}\n",
    "        # 计算相关\n",
    "        relevances = self.cal_mics(dfx, y)\n",
    "        # print('与y的关联性:\\n{}'.format(relevances))\n",
    "        last_sel = relevances.idxmax()\n",
    "        selected.append(last_sel)\n",
    "        relevances = relevances.to_dict()\n",
    "        print('选中：{}'.format(last_sel))\n",
    "        # 冗余-初始化为0.0\n",
    "        redundances = defaultdict(float)\n",
    "\n",
    "        while len(selected) < dfx.shape[0] and len(selected) < n:\n",
    "            mr = -np.inf\n",
    "            new_sel = None\n",
    "            for cc in dfx.columns:\n",
    "                if cc not in selected:\n",
    "                    redundances[cc] += self.cal_mic(dfx[cc], dfx[last_sel])\n",
    "                    # 综合考虑相关性和冗余性\n",
    "                    _mrmr = relevances[cc] - (redundances[cc] / len(selected))\n",
    "                    if _mrmr > mr:\n",
    "                        mr = _mrmr\n",
    "                        new_sel = cc\n",
    "            print('选中：{}'.format(new_sel))\n",
    "            selected.append(new_sel)\n",
    "            last_sel = new_sel\n",
    "        # print('x的冗余性：\\n{}'.format(redundances))\n",
    "        return selected\n",
    "    \n",
    "    def _by_RFE(self, mm, method, step=1):\n",
    "        \"\"\"Wrapper方法\"\"\"\n",
    "        ret = RFE(estimator=mm,\n",
    "                  n_features_to_select=self.n_features_to_select,\n",
    "                  step=step).fit(self.X, self.y)\n",
    "        return self._return(ret, method)\n",
    "    \n",
    "    def by_RFE_lr(self, args=None):\n",
    "        return self._by_RFE(LogisticRegression(), 'by_REF_lr')\n",
    "\n",
    "    def by_RFE_svm(self, args=None):\n",
    "        return self._by_RFE(LinearSVC(), 'by_REF_svm')\n",
    "    \n",
    "    def _by_model(self, mm, method):\n",
    "        \"\"\"Embedded方法\"\"\"\n",
    "        ret = SelectFromModel(mm).fit(self.X, self.y)\n",
    "        return self._return(ret, method)\n",
    "    \n",
    "    def by_gbdt(self):\n",
    "        return self._by_model(GradientBoostingClassifier(), 'by_gbdt')\n",
    "\n",
    "    def by_rf(self):\n",
    "        return self._by_model(RandomForestClassifier(), 'by_rf')\n",
    "\n",
    "    def by_et(self):\n",
    "        return self._by_model(ExtraTreesClassifier(), 'by_et')\n",
    "\n",
    "    def by_lr(self, C=0.1):\n",
    "        return self._by_model(LogisticRegression(penalty='l1', C=C, solver='liblinear'), 'by_lr')\n",
    "\n",
    "    def by_svm(self, C=0.01):\n",
    "        return self._by_model(LinearSVC(penalty='l1', C=C, dual=False), 'by_svm')\n",
    "    \n",
    "    def example_10_methods(self):\n",
    "        name = [\n",
    "            'by_var', 'by_max_info', 'by_pearson', 'by_RFE_svm', 'by_RFE_lr',\n",
    "            'by_svm', 'by_lr', 'by_et', 'by_rf', 'by_gbdt'\n",
    "        ]\n",
    "        # {0:col_0,1:col_1}\n",
    "        map_index_cols = dict(zip(range(len(self.cols)), self.cols))\n",
    "\n",
    "        # 执行特征选择算法\n",
    "        method_dict = {}\n",
    "        method_dict['by_var'] = self.by_var()\n",
    "        method_dict['by_pearson'] = self.by_pearson()\n",
    "        method_dict['by_max_info'] = self.by_max_info()\n",
    "        method_dict['by_RFE_svm'] = self.by_RFE_svm()\n",
    "        method_dict['by_RFE_lr'] = self.by_RFE_lr()\n",
    "        method_dict['by_svm'] = self.by_svm()\n",
    "        method_dict['by_lr'] = self.by_lr()\n",
    "        method_dict['by_et'] = self.by_et()\n",
    "        method_dict['by_rf'] = self.by_rf()\n",
    "        method_dict['by_gbdt'] = self.by_gbdt()\n",
    "\n",
    "        # 打平选中特征的list\n",
    "        selected = [j for i in list(method_dict.values()) for j in i]\n",
    "\n",
    "        # 构建特征被哪些方法选中：0，1 表示\n",
    "        dicts01 = {}\n",
    "        for nm in name:\n",
    "            dicts01[nm] = [\n",
    "                1 if i in list(method_dict[nm]) else 0\n",
    "                for i in range(len(self.cols))\n",
    "            ]\n",
    "\n",
    "        # 构建结果统计用的DataFrame\n",
    "        stat_f = pd.Series(selected).value_counts().reset_index()\n",
    "        stat_f.columns = ['col_idx', 'count']\n",
    "        stat_f['feature'] = stat_f.col_idx.map(map_index_cols)\n",
    "\n",
    "        # 升序排列匹配模型选择方法的值\n",
    "        stat_f.sort_values(by='col_idx', ascending=True, inplace=True)\n",
    "\n",
    "        for i in name:\n",
    "            stat_f[i] = dicts01[i]\n",
    "\n",
    "        # 按照特征被选中个数降序排列, 个数相同的情况下按照idx升序排列\n",
    "        stat_f.sort_values(by=['count', 'col_idx'],\n",
    "                           ascending=[False, True],\n",
    "                           inplace=True)\n",
    "\n",
    "        selected = stat_f['feature'][:self.n_features_to_select].tolist()\n",
    "        print('*' * 10 + 'remains columns:\\n{}'.format(selected))\n",
    "\n",
    "        return selected, stat_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 5)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "\n",
    "# 转化为df\n",
    "X = pd.DataFrame.from_records(data=data.data, columns=data.feature_names)\n",
    "df = X\n",
    "df['target'] = data.target\n",
    "df = df[:100].copy()\n",
    "# df = df.copy()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col = [cc for cc in df.columns if cc != 'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.n_features_to_select: 3\n"
     ]
    }
   ],
   "source": [
    "FF = FeatureFilter(df[x_col], df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***by_var:\n",
      "  remain feature index:\n",
      "  [0 1 2 3]\n",
      "  removed feature index:\n",
      "  []\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FF.by_var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***by_chi2:\n",
      "  remain feature index:\n",
      "  [0 2 3]\n",
      "  removed feature index:\n",
      "  [1]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FF.by_chi2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***by_pearson:\n",
      "  remain feature index:\n",
      "  [0 2 3]\n",
      "  removed feature index:\n",
      "  [1]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FF.by_pearson()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***by_mi:\n",
      "  remain feature index:\n",
      "  [0 2 3]\n",
      "  removed feature index:\n",
      "  [1]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FF.by_mi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***by_max_info:\n",
      "  remain feature index:\n",
      "  [0 2 3]\n",
      "  removed feature index:\n",
      "  [1]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FF.by_max_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***f_regression:\n",
      "  remain feature index:\n",
      "  [0 2 3]\n",
      "  removed feature index:\n",
      "  [1]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FF.by_f_regression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***f_classif:\n",
      "  remain feature index:\n",
      "  [0 2 3]\n",
      "  removed feature index:\n",
      "  [1]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FF.by_f_classif()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***by_iv:\n",
      "  remain feature index:\n",
      "  [2 3]\n",
      "  removed feature index:\n",
      "  [0, 1]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([2, 3], dtype=int64), {0: 3.456, 1: 3.2406, 2: 7.6676, 3: 7.6676})"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FF.by_iv(threshold=4, return_iv=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After filter，remains:3\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['petal length (cm)', 'sepal length (cm)', 'sepal width (cm)']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_iv = toad.quality(df, target='target')\n",
    "orderly_cols = list(data_iv.index.values)\n",
    "FF.filter_bycorr_with_orderly_cols(df, orderly_cols, columns=x_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "选中：petal length (cm)\n",
      "选中：sepal width (cm)\n",
      "选中：petal width (cm)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['petal length (cm)', 'sepal width (cm)', 'petal width (cm)']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FF.mrmr(df[x_col], df['target'], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3、包裹法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureWrapper():\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: pandas.DataFrame\n",
    "        数据集. \n",
    "    y: pandas.series or nparray\n",
    "        目标变量.\n",
    "    n_features_to_select: \n",
    "        选择特征的数.\n",
    "    only_get_index: \n",
    "        是否只返回选中特征的索引.\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, n_features_to_select=None, only_get_index=True):\n",
    "        self.cols = X.columns.tolist()\n",
    "        self.X = np.array(X)\n",
    "        self.y = np.array(y)\n",
    "        self.x_index = range(self.X.shape[1])\n",
    "        self.only_get_index = only_get_index\n",
    "        self.n_features_to_select = n_features_to_select\n",
    "        if n_features_to_select is None:\n",
    "            self.n_features_to_select = int(np.ceil(2 / 3 * self.X.shape[1]))\n",
    "            print('self.n_features_to_select:', self.n_features_to_select)\n",
    "        self.removed = []\n",
    "    \n",
    "    def _log(self, index, method):\n",
    "        print('***{}:'.format(method))\n",
    "        print('  remain feature index:\\n  {}'.format(index))\n",
    "        rmvd = list_diff(self.x_index, index)\n",
    "        self.removed += rmvd\n",
    "        print('  removed feature index:\\n  {}\\n'.format(rmvd))\n",
    "\n",
    "    def _return(self, ret, method):\n",
    "        # True代表该特征被选中\n",
    "        index = ret.get_support(indices=True)\n",
    "        self._log(index, method)\n",
    "\n",
    "        if self.only_get_index == True:\n",
    "            return index\n",
    "        else:  #返回筛选之后的X\n",
    "            return ret.transform(self.X) \n",
    "    \n",
    "    def _return_index(self, index, method):\n",
    "        # True代表该特征被选中\n",
    "        self._log(index, method)\n",
    "\n",
    "        if self.only_get_index == True:\n",
    "            return index\n",
    "        else:  #返回筛选之后的X\n",
    "            return self.X[:, index]\n",
    "    \n",
    "    def _by_RFE(self, mm, method, step=1):\n",
    "        \"\"\"Wrapper方法\"\"\"\n",
    "        ret = RFE(estimator=mm,\n",
    "                  n_features_to_select=self.n_features_to_select,\n",
    "                  step=step).fit(self.X, self.y)\n",
    "        return self._return(ret, method)\n",
    "    \n",
    "    def by_RFE_lr(self, args=None):\n",
    "        return self._by_RFE(LogisticRegression(), 'by_REF_lr')\n",
    "\n",
    "    def by_RFE_svm(self, args=None):\n",
    "        return self._by_RFE(LinearSVC(), 'by_REF_svm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.n_features_to_select: 3\n"
     ]
    }
   ],
   "source": [
    "FW = FeatureWrapper(df[x_col], df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***by_REF_lr:\n",
      "  remain feature index:\n",
      "  [1 2 3]\n",
      "  removed feature index:\n",
      "  [0]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FW.by_RFE_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***by_REF_svm:\n",
      "  remain feature index:\n",
      "  [1 2 3]\n",
      "  removed feature index:\n",
      "  [0]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FW.by_RFE_svm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4、嵌入法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEmbedded():\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: pandas.DataFrame\n",
    "        数据集. \n",
    "    y: pandas.series or nparray\n",
    "        目标变量.\n",
    "    n_features_to_select: \n",
    "        选择特征的数.\n",
    "    only_get_index: \n",
    "        是否只返回选中特征的索引.\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, n_features_to_select=None, only_get_index=True):\n",
    "        self.cols = X.columns.tolist()\n",
    "        self.X = np.array(X)\n",
    "        self.y = np.array(y)\n",
    "        self.x_index = range(self.X.shape[1])\n",
    "        self.only_get_index = only_get_index\n",
    "        self.n_features_to_select = n_features_to_select\n",
    "        if n_features_to_select is None:\n",
    "            self.n_features_to_select = int(np.ceil(2 / 3 * self.X.shape[1]))\n",
    "            print('self.n_features_to_select:', self.n_features_to_select)\n",
    "        self.removed = []\n",
    "    \n",
    "    def _log(self, index, method):\n",
    "        print('***{}:'.format(method))\n",
    "        print('  remain feature index:\\n  {}'.format(index))\n",
    "        rmvd = list_diff(self.x_index, index)\n",
    "        self.removed += rmvd\n",
    "        print('  removed feature index:\\n  {}\\n'.format(rmvd))\n",
    "\n",
    "    def _return(self, ret, method):\n",
    "        # True代表该特征被选中\n",
    "        index = ret.get_support(indices=True)\n",
    "        self._log(index, method)\n",
    "\n",
    "        if self.only_get_index == True:\n",
    "            return index\n",
    "        else:  #返回筛选之后的X\n",
    "            return ret.transform(self.X) \n",
    "    \n",
    "    def _return_index(self, index, method):\n",
    "        # True代表该特征被选中\n",
    "        self._log(index, method)\n",
    "\n",
    "        if self.only_get_index == True:\n",
    "            return index\n",
    "        else:  #返回筛选之后的X\n",
    "            return self.X[:, index]\n",
    "    \n",
    "    def _by_model(self, mm, method):\n",
    "        \"\"\"Embedded方法\"\"\"\n",
    "        ret = SelectFromModel(mm).fit(self.X, self.y)\n",
    "        return self._return(ret, method)\n",
    "    \n",
    "    def by_gbdt(self):\n",
    "        return self._by_model(GradientBoostingClassifier(), 'by_gbdt')\n",
    "\n",
    "    def by_rf(self):\n",
    "        return self._by_model(RandomForestClassifier(), 'by_rf')\n",
    "\n",
    "    def by_et(self):\n",
    "        return self._by_model(ExtraTreesClassifier(), 'by_et')\n",
    "\n",
    "    def by_lr(self, C=0.1):\n",
    "        return self._by_model(LogisticRegression(penalty='l1', C=C, solver='liblinear'), 'by_lr')\n",
    "\n",
    "    def by_svm(self, C=0.01):\n",
    "        return self._by_model(LinearSVC(penalty='l1', C=C, dual=False), 'by_svm')\n",
    "    \n",
    "    def example_10_methods(self):\n",
    "        name = [\n",
    "            'by_svm', 'by_lr', 'by_et', 'by_rf', 'by_gbdt'\n",
    "        ]\n",
    "        # {0:col_0,1:col_1}\n",
    "        map_index_cols = dict(zip(range(len(self.cols)), self.cols))\n",
    "\n",
    "        # 执行特征选择算法\n",
    "        method_dict = {}\n",
    "        method_dict['by_svm'] = self.by_svm()\n",
    "        method_dict['by_lr'] = self.by_lr()\n",
    "        method_dict['by_et'] = self.by_et()\n",
    "        method_dict['by_rf'] = self.by_rf()\n",
    "        method_dict['by_gbdt'] = self.by_gbdt()\n",
    "\n",
    "        # 打平选中特征的list\n",
    "        selected = [j for i in list(method_dict.values()) for j in i]\n",
    "\n",
    "        # 构建特征被哪些方法选中：0，1 表示\n",
    "        dicts01 = {}\n",
    "        for nm in name:\n",
    "            dicts01[nm] = [\n",
    "                1 if i in list(method_dict[nm]) else 0\n",
    "                for i in range(len(self.cols))\n",
    "            ]\n",
    "\n",
    "        # 构建结果统计用的DataFrame\n",
    "        stat_f = pd.Series(selected).value_counts().reset_index()\n",
    "        stat_f.columns = ['col_idx', 'count']\n",
    "        stat_f['feature'] = stat_f.col_idx.map(map_index_cols)\n",
    "\n",
    "        # 升序排列匹配模型选择方法的值\n",
    "        stat_f.sort_values(by='col_idx', ascending=True, inplace=True)\n",
    "\n",
    "        for i in name:\n",
    "            stat_f[i] = dicts01[i]\n",
    "\n",
    "        # 按照特征被选中个数降序排列, 个数相同的情况下按照idx升序排列\n",
    "        stat_f.sort_values(by=['count', 'col_idx'],\n",
    "                           ascending=[False, True],\n",
    "                           inplace=True)\n",
    "\n",
    "        selected = stat_f['feature'][:self.n_features_to_select].tolist()\n",
    "        print('*' * 10 + 'remains columns:\\n{}'.format(selected))\n",
    "\n",
    "        return selected, stat_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.n_features_to_select: 3\n"
     ]
    }
   ],
   "source": [
    "FE = FeatureEmbedded(df[x_col], df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***by_gbdt:\n",
      "  remain feature index:\n",
      "  [2 3]\n",
      "  removed feature index:\n",
      "  [0, 1]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 3], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FE.by_gbdt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***by_rf:\n",
      "  remain feature index:\n",
      "  [2 3]\n",
      "  removed feature index:\n",
      "  [0, 1]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 3], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FE.by_rf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***by_et:\n",
      "  remain feature index:\n",
      "  [2 3]\n",
      "  removed feature index:\n",
      "  [0, 1]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 3], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FE.by_et()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***by_lr:\n",
      "  remain feature index:\n",
      "  [1 2]\n",
      "  removed feature index:\n",
      "  [0, 3]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FE.by_lr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***by_svm:\n",
      "  remain feature index:\n",
      "  [1 2]\n",
      "  removed feature index:\n",
      "  [0, 3]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FE.by_svm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.n_features_to_select: 3\n",
      "***by_var:\n",
      "  remain feature index:\n",
      "  [0 1 2 3]\n",
      "  removed feature index:\n",
      "  []\n",
      "\n",
      "***by_pearson:\n",
      "  remain feature index:\n",
      "  [0 2 3]\n",
      "  removed feature index:\n",
      "  [1]\n",
      "\n",
      "***by_max_info:\n",
      "  remain feature index:\n",
      "  [0 2 3]\n",
      "  removed feature index:\n",
      "  [1]\n",
      "\n",
      "***by_REF_svm:\n",
      "  remain feature index:\n",
      "  [1 2 3]\n",
      "  removed feature index:\n",
      "  [0]\n",
      "\n",
      "***by_REF_lr:\n",
      "  remain feature index:\n",
      "  [1 2 3]\n",
      "  removed feature index:\n",
      "  [0]\n",
      "\n",
      "***by_svm:\n",
      "  remain feature index:\n",
      "  [1 2]\n",
      "  removed feature index:\n",
      "  [0, 3]\n",
      "\n",
      "***by_lr:\n",
      "  remain feature index:\n",
      "  [1 2]\n",
      "  removed feature index:\n",
      "  [0, 3]\n",
      "\n",
      "***by_et:\n",
      "  remain feature index:\n",
      "  [2 3]\n",
      "  removed feature index:\n",
      "  [0, 1]\n",
      "\n",
      "***by_rf:\n",
      "  remain feature index:\n",
      "  [2 3]\n",
      "  removed feature index:\n",
      "  [0, 1]\n",
      "\n",
      "***by_gbdt:\n",
      "  remain feature index:\n",
      "  [2 3]\n",
      "  removed feature index:\n",
      "  [0, 1]\n",
      "\n",
      "**********remains columns:\n",
      "['petal length (cm)', 'petal width (cm)', 'sepal width (cm)']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['petal length (cm)', 'petal width (cm)', 'sepal width (cm)'],\n",
       "    col_idx  count            feature  by_var  by_max_info  by_pearson  \\\n",
       " 0        2     10  petal length (cm)       1            1           1   \n",
       " 1        3      8   petal width (cm)       1            1           1   \n",
       " 2        1      5   sepal width (cm)       1            0           0   \n",
       " 3        0      3  sepal length (cm)       1            1           1   \n",
       " \n",
       "    by_RFE_svm  by_RFE_lr  by_svm  by_lr  by_et  by_rf  by_gbdt  \n",
       " 0           1          1       1      1      1      1        1  \n",
       " 1           1          1       0      0      1      1        1  \n",
       " 2           1          1       1      1      0      0        0  \n",
       " 3           0          0       0      0      0      0        0  )"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FF = FeatureFilter(df[x_col], df['target'])\n",
    "FF.example_10_methods()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5、逐步回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = StepWise(X[x_col], X['target'])\n",
    "S.bf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2, drop_vars = toad.selection.stepwise(df, target='target', return_drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
